
## 创建
### 库

### 表

#### 常用类型
- 对于实际去重数量较少的类型可以使用，比如 `type lowCardinality(String)
  和 enum 类型低层存储都是数字，但是更加灵活
![[IMG-20250930135303046.png]]
## 常见问题
### 一、插入批次大小的合理范围

一次插入操作会生成一个 Part（特殊情况如数据量过大可能拆分为多个，但通常为 1 个），而一个 Part 包含的 Granule 数量由`index_granularity`（默认 8192 行）决定（Granule 数量 = 插入总行数 /index_granularity，向上取整）。

插入批次的合理大小需要平衡**Part 数量**和**单 Part 体积**，建议参考以下原则：

#### 1. 推荐范围

- **行数**：每次插入 10 万～100 万行（根据单条数据大小调整）。
- **数据量**：每次插入 100MB ~ 1GB（ClickHouse 对大批次插入的处理更高效）。

#### 2. 为什么这样设置？

- **避免过小批次**：如果每次插入几千行（如 1 万行以下），会生成大量小 Part（例如 100 次插入生成 100 个 Part）。过多 Part 会导致：
    - 元数据管理开销增加（ClickHouse 需要维护每个 Part 的索引和元信息）。
    - 查询时需要扫描多个 Part 的索引，降低过滤效率。
- **避免过大批次**：如果单次插入超过 10GB 或数千万行，可能导致：
    - 插入时内存占用过高（ClickHouse 需要在内存中暂存数据并排序）。
    - 单个 Part 过大，后续合并时耗时更长，影响查询稳定性。

#### 3. 如何尽可能提高单批插入数量


### 二、完整的查询过滤逻辑（结合分区、Part、Granule）

ClickHouse 的查询过滤是**多层级递进**的，从宏观到微观依次过滤，最大限度减少需要读取的数据量。以你的表（`posts_ordered`，无显式分区键，主键为`(PostTypeId, toDate(CreationDate))`）为例，完整流程如下：

#### 1. 第一层：分区过滤（Partition Filter）

- **依据**：表的`PARTITION BY`定义（若未指定，默认所有数据在`all`分区）。
- **逻辑**：根据查询条件中的分区键（如有），过滤出需要扫描的分区。
    - 例如：若表按`toYYYYMM(CreationDate)`分区，查询`CreationDate >= '2024-01-01'`会过滤出`202401`及之后的分区，跳过 2023 年的分区。
    - 你的表无显式分区键，因此此步骤会保留唯一的`all`分区，无过滤。

#### 2. 第二层：Part 过滤（Part Filter）

- **依据**：每个 Part 的**主键范围信息**（存储在 Part 的元数据中，记录该 Part 内主键字段的最小值和最大值）。
- **逻辑**：在第一步过滤后的分区内，遍历所有 Part，仅保留主键范围与查询条件有交集的 Part。
    - 你的查询条件是`PostTypeId = 'Question'`（即`PostTypeId=1`）和`CreationDate >= '2024-01-01'`（即`toDate(CreationDate) >= 2024-01-01`）。
    - 每个 Part 的元数据中记录了该 Part 内`PostTypeId`的最小 / 最大值和`toDate(CreationDate)`的最小 / 最大值。例如：
        - 若某 Part 的`PostTypeId`范围是`[2, 2]`（全是 Answer），会被直接过滤。
        - 若某 Part 的`toDate(CreationDate)`范围是`[2023-12-01, 2023-12-31]`，会被直接过滤。
    - 最终保留的 Part 是那些`PostTypeId`包含 1、且`toDate(CreationDate)` >= 2024-01-01 的 Part（你的例子中是 14 个 Part 都符合，可能因为这些 Part 的主键范围与条件有交集）。

#### 3. 第三层：Granule 过滤（Granule Filter）
![[IMG-20250930165607180.png]]
- **依据**：每个 Part 内部的**Granule 索引**（存储在`.idx`文件中，记录每个 Granule 的主键范围）。
- **逻辑**：在第二步过滤后的每个 Part 内，遍历所有 Granule，仅保留主键范围与查询条件有交集的 Granule。
    - 每个 Granule 的索引记录了该 Granule 内`PostTypeId`的最小 / 最大值和`toDate(CreationDate)`的最小 / 最大值。
    - 例如：某 Part 内有 100 个 Granule，其中只有 39 个 Granule 的`PostTypeId=1`且`toDate(CreationDate)>=2024-01-01`，则只需要读取这 39 个 Granule（对应你的`Granules: 39/7578`）。

#### 4. 第四层：行级过滤（Row Filter）

- **依据**：实际数据行的字段值。
- **逻辑**：读取第三步过滤后的 Granule 数据，对每行进行精确过滤（虽然 Granule 索引已过滤大部分不匹配数据，但可能存在边界情况，需最终校验）。

#### 总结：过滤逻辑的核心目的

从分区 → Part → Granule → 行，每层过滤都在**减少下一层需要处理的数据量**，最终只读取极少部分（甚至 0.5% 以下）的原始数据，这是 ClickHouse 高性能的关键原因。

## 实践建议

1. 插入时尽量控制批次在 100MB~1GB，避免过多小 Part。
2. 若表数据量大（超过 100GB），建议添加合理的`PARTITION BY`（如按`toYYYYMM(CreationDate)`分区），利用分区过滤减少需要扫描的 Part 数量。
3. 主键设计需包含高频过滤字段（如你的`PostTypeId`和`CreationDate`），确保 Part 和 Granule 过滤能有效生效。